from django.shortcuts import render
from rest_framework import generics, permissions, status
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from rest_framework.views import APIView
from rest_framework_simplejwt.exceptions import TokenError
from rest_framework_simplejwt.tokens import RefreshToken
from rest_framework_simplejwt.views import TokenObtainPairView

from serializers import (
    CustomTokenObtainPairSerializer,
    RegisterSerializer,
    UpdateUserSerializer,
)

from .models import Users


class RegisterView(
    generics.CreateAPIView
):  # íšŒì›ê°€ì… CreateAPIViewëŠ” POST ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ë•Œë¬¸ì— ë”°ë¡œ post() ë©”ì„œë“œë¥¼ ì •ì˜í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
    queryset = Users.objects.all()
    serializer_class = RegisterSerializer
    permission_classes = [permissions.AllowAny]

    # ë””ë²„ê¹…ìš©
    def perform_create(self, serializer):
        print(
            "ğŸ”¥ perform_create() í˜¸ì¶œë¨ - serializer.validated_data:",
            serializer.validated_data,
        )
        serializer.save()


"""
ë¡œê·¸ì•„ì›ƒì€ í”„ë¡ íŠ¸ì—ì„œ Refresh í† í°ì„ ë³´ë‚´ë©´ ì„œë²„ì—ì„œ Refresh í† í°ì„ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ë§Œ
ë¡œê·¸ì¸ í•˜ë©´ í´ë¼ì´ì–¸íŠ¸ëŠ” ë‘ê°œì˜ í† í° ëª¨ë‘ì €ì¥í•¨
í”„ë¡ íŠ¸ì—ì„œ ë³´ë‚´ì£¼ë©´ ìì²´ì ìœ¼ë¡œ ì²˜ë¦¬
* í”„ë¡ íŠ¸ëŠ” ê°€ëŠ¥í•œ ê²½ìš° Refresh í† í°ì„ HttpOnly Cookieì— ì €ì¥í•˜ëŠ” ê²ƒì´ ì•ˆì „
"""


class LogoutView(APIView):
    permission_classes = [
        permissions.IsAuthenticated
    ]  # í”„ë¡ íŠ¸ì—ì„œ ë°”ë””ì— refreshìˆì–´ì•¼í•¨ ( "refresh" : "ë¦¬í”„ë ˆì‰ í† í°")

    def post(self, request):
        refresh_token = request.data.get("refresh")

        if not refresh_token:
            return Response({"detail": "Refresh token is required."}, status=400)

        try:
            token = RefreshToken(refresh_token)
            token.blacklist()
            return Response({"detail": "ë¡œê·¸ì•„ì›ƒ"}, status=204)
        except TokenError as e:
            return Response({"detail": str(e)}, status=400)
        except Exception:
            return Response({"detail": "Invalid request."}, status=400)


class LoginView(TokenObtainPairView):
    serializer_class = CustomTokenObtainPairSerializer


class DeleteUserView(APIView):  # í”„ë¡ íŠ¸ì—ì„œ í—¤ë”ì— access_tokenìˆì–´ì•¼í•¨
    permission_classes = [IsAuthenticated]

    def delete(self, request):
        user = request.user
        user.delete()
        return Response(
            {"detail": "íšŒì› íƒˆí‡´ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}, status=status.HTTP_204_NO_CONTENT
        )


class UpdateUserView(APIView):
    permission_classes = [IsAuthenticated]  # í”„ë¡ íŠ¸ì—ì„œ í—¤ë”ì— access_tokenìˆì–´ì•¼í•¨

    def put(self, request):
        user = request.user  # í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ê°€ì ¸ì˜¤ê¸°
        serializer = UpdateUserSerializer(
            user, data=request.data, partial=True
        )  # partial=Trueë¡œ í•˜ë©´ ì¼ë¶€ë§Œ ìˆ˜ì • ê°€ëŠ¥
        if serializer.is_valid():
            serializer.save()
            return Response(
                {"detail": "íšŒì›ì •ë³´ê°€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤."},
                status=status.HTTP_200_OK,
            )
        else:
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


################################################################################################
# prompt test
################################################################################################
from django.conf import settings
from django.http import JsonResponse, StreamingHttpResponse
from google import genai
from django.views.decorators.csrf import csrf_exempt
import json

import os
import pandas as pd
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate

from sqlalchemy import create_engine
from langchain_chroma import Chroma
from sentence_transformers import SentenceTransformer
from langchain.embeddings.base import Embeddings

from langgraph.graph import StateGraph, END
from langchain_core.tools import tool
from langchain_core.runnables import RunnableLambda
from typing_extensions import TypedDict, Optional

from langchain_experimental.agents.agent_toolkits import create_csv_agent
from langchain_google_genai import ChatGoogleGenerativeAI
import numpy as np

# =============================================
# GEMINI API KEY ë“±ë¡
# =============================================
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
os.environ["GOOGLE_API_KEY"] = api_key

# =============================================
# MySQL ì—°ê²° ì„¤ì •
# =============================================
user = os.getenv("DB_USER")
password = os.getenv("DB_PASSWORD")
host = os.getenv("SERVER_HOST")
port = "3306"
database = os.getenv("DB_NAME")


# =============================================
# ì„ë² ë”© ëª¨ë¸ ì •ì˜
# =============================================
class SentenceTransformerEmbeddings(Embeddings):
    def __init__(self, model):
        self.model = model

    def embed_documents(self, texts):
        return self.model.encode(texts, show_progress_bar=False).tolist()

    def embed_query(self, text):
        return self.model.encode([text], show_progress_bar=False)[0].tolist()


class StateDict(TypedDict):
    user_prompt: str
    product1: str
    product2: str
    docs: Optional[str]
    context: Optional[str]
    llm_response: Optional[str]


@tool(description="ë¦¬ë·° ë° ì œí’ˆ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  contextë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
def load_data(user_prompt: str, product1: str, product2: str) -> dict:

    if not user_prompt:
        raise ValueError("Prompt is required")  # Django response ë§ê³  ì˜ˆì™¸ë¡œ ì²˜ë¦¬

    # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    embedding_model = SentenceTransformer("intfloat/multilingual-e5-large-instruct")
    embeddings = SentenceTransformerEmbeddings(embedding_model)

    # ë‘ ê°œì˜ ChromaDB ë¶ˆëŸ¬ì˜¤ê¸°
    vectordb1 = Chroma(
        persist_directory=f"./vectordb/reviews/product_{product1}",
        collection_name=f"reviews_product_{product1}",
        embedding_function=embeddings,
    )
    vectordb2 = Chroma(
        persist_directory=f"./vectordb/reviews/product_{product2}",
        collection_name=f"reviews_product_{product2}",
        embedding_function=embeddings,
    )

    # retriever ê±°ë¦¬ ê¸°ë°˜ ë¦¬ë·° ê²€ìƒ‰
    retriever1 = vectordb1.as_retriever(search_kwargs={"k": 30})
    retriever2 = vectordb2.as_retriever(search_kwargs={"k": 30})

    # MySQLì—ì„œ product ì •ë³´ ë¡œë“œ
    engine = create_engine(
        f"mysql+pymysql://{user}:{password}@{host}:{port}/{database}?charset=utf8mb4"
    )
    query = f"SELECT * FROM products WHERE id IN ({product1}, {product2})"
    products_df = pd.read_sql(query, con=engine)

    # retrieverë¡œ context (ë¦¬ë·°)ë§Œ ë°›ìŒ
    docs1 = retriever1.invoke(user_prompt)
    docs2 = retriever2.invoke(user_prompt)

    # context: ë¦¬ë·° + ë³„ë„ë¡œ ë¶ˆëŸ¬ì˜¨ ë©”íƒ€ë°ì´í„°ë¥¼ ì¡°í•©
    reviews_data1 = "\n".join(
        [
            f"[ì œí’ˆ1 ë¦¬ë·°]: {doc.page_content}\n[ë©”íƒ€ë°ì´í„°]: {doc.metadata}"
            for doc in docs1
        ]
    )
    reviews_data2 = "\n".join(
        [
            f"[ì œí’ˆ2 ë¦¬ë·°]: {doc.page_content}\n[ë©”íƒ€ë°ì´í„°]: {doc.metadata}"
            for doc in docs2
        ]
    )
    products_data = "\n".join(
        [f"[ì œí’ˆ ì •ë³´]: {row.to_dict()}" for _, row in products_df.iterrows()]
    )

    final_docs = f"{reviews_data1}\n\n{reviews_data2}\n\n{products_data}"

    return {"docs": final_docs, "context": user_prompt}


@csrf_exempt
def gemini_streaming(request):
    if request.method != "POST":
        return JsonResponse({"error": "Only POST method is allowed"}, status=405)

    try:
        body = json.loads(request.body)
        user_prompt = body.get("user_prompt", "").strip()
        product1 = body.get("product1", "").strip()
        product2 = body.get("product2", "").strip()

        if not user_prompt:
            return JsonResponse({"error": "Prompt is required"}, status=400)

        state = {
            "user_prompt": user_prompt,
            "product1": product1,
            "product2": product2,
            "docs": None,
            "context": None,
            "llm_response": None,
        }

        result = app.invoke(state)  # LangGraph ì‹¤í–‰

        final_docs = result["docs"]
        user_prompt = result["context"]

    except Exception as e:
        import traceback, sys

        traceback.print_exc(file=sys.stderr)
        return JsonResponse({"error": f"Invalid input: {str(e)}"}, status=400)

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ë„ˆëŠ” ë‘ ì œí’ˆì˜ ë¦¬ë·° ë°ì´í„°ë¥¼ ë¹„êµí•˜ê³  ë¶„ì„í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì•¼. 
                        íƒ€ì‚¬ ì œí’ˆ ëŒ€ë¹„ ìì‚¬ ì œí’ˆì˜ ì¥ë‹¨ì ì„ íŒŒì•…í•˜ê³  ê°œì„ ì ì„ ì°¾ê¸° ìœ„í•´ 
                        ê·¸ì— ë§ëŠ” ë¦¬í¬íŠ¸ ë‚´ë¶€ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µ í•´ì¤˜.
                        product1ì€ ìì‚¬ ì œí’ˆì´ê³ , product2ëŠ” ê²½ìŸì‚¬ ì œí’ˆì´ì•¼.

                        ì œí•œëœ í† í° ì•ˆì—ì„œ ë‚´ìš©ì´ ë¶€ì •í™•í•˜ê±°ë‚˜ ë‹µë³€ì´ ëŠê¸°ëŠ” ë“± ì œí’ˆ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ëª¨í˜¸í•´ì§€ë©´ ì•ˆë¼.
                        ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ê³ , ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ëª¨ë¥¸ë‹¤ê³  ë‹µí•´ì¤˜.""",
            ),
            ("user", "ìš”ì²­: {user_prompt}\n\nContext:\n{final_docs}"),
        ]
    )

    formatted_prompt = prompt.format(user_prompt=user_prompt, final_docs=final_docs)

    model_agent = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)

    import pandas as pd

    # product1_agent = create_csv_agent(
    #     model_agent,
    #     f"./review_csv/{product1}.csv",
    #     verbose=True,
    #     allow_dangerous_code=True,
    # )
    try:
        answer = product1_agent.run(user_prompt)  # ë˜ëŠ” invoke({...})
    except Exception as e:
        answer = f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}"

    # Gemini API
    client = genai.Client(api_key=settings.GEMINI_API_KEY)
    stream = client.models.generate_content_stream(
        model="gemini-2.0-flash",
        contents=formatted_prompt,
        # eneration_config={
        # max_output_tokens":state["input"]["max_tokens"]
        #
    )

    def gen():
        # if type in "graph":
        # try:
        #     yield f"data: {json.dumps({'text': answer})}\n\n"
        # except Exception as e:
        #     yield f"data: {json.dumps({'error': str(e)})}\n\n"

        # else:
        try:
            for chunk in stream:
                # Check if chunk has text content
                if hasattr(chunk, "text") and chunk.text:
                    print(f"Sending chunk: {chunk.text[:50]}...")  # Debug print
                    # Wrap with SSE format
                    yield f"data: {json.dumps({'text': chunk.text})}\n\n"
        except Exception as e:
            print(f"Streaming error: {e}")
            yield f"data: {json.dumps({'error': str(e)})}\n\n"

    return StreamingHttpResponse(
        gen(),
        content_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
    )


builder = StateGraph(StateDict)
builder.add_node("load_data", load_data)
builder.set_entry_point("load_data")
builder.set_finish_point("load_data")
app = builder.compile()
