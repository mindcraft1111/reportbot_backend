from django.shortcuts import render
from rest_framework import generics, permissions, status
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from rest_framework.views import APIView
from rest_framework_simplejwt.exceptions import TokenError
from rest_framework_simplejwt.tokens import RefreshToken
from rest_framework_simplejwt.views import TokenObtainPairView

from serializers import (
    CustomTokenObtainPairSerializer,
    RegisterSerializer,
    UpdateUserSerializer,
)

from .models import Users


class RegisterView(
    generics.CreateAPIView
):  # íšŒì›ê°€ì… CreateAPIViewëŠ” POST ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ë•Œë¬¸ì— ë”°ë¡œ post() ë©”ì„œë“œë¥¼ ì •ì˜í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
    queryset = Users.objects.all()
    serializer_class = RegisterSerializer
    permission_classes = [permissions.AllowAny]

    # ë””ë²„ê¹…ìš©
    def perform_create(self, serializer):
        print(
            "ğŸ”¥ perform_create() í˜¸ì¶œë¨ - serializer.validated_data:",
            serializer.validated_data,
        )
        serializer.save()


"""
ë¡œê·¸ì•„ì›ƒì€ í”„ë¡ íŠ¸ì—ì„œ Refresh í† í°ì„ ë³´ë‚´ë©´ ì„œë²„ì—ì„œ Refresh í† í°ì„ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ë§Œ
ë¡œê·¸ì¸ í•˜ë©´ í´ë¼ì´ì–¸íŠ¸ëŠ” ë‘ê°œì˜ í† í° ëª¨ë‘ì €ì¥í•¨
í”„ë¡ íŠ¸ì—ì„œ ë³´ë‚´ì£¼ë©´ ìì²´ì ìœ¼ë¡œ ì²˜ë¦¬
* í”„ë¡ íŠ¸ëŠ” ê°€ëŠ¥í•œ ê²½ìš° Refresh í† í°ì„ HttpOnly Cookieì— ì €ì¥í•˜ëŠ” ê²ƒì´ ì•ˆì „
"""


class LogoutView(APIView):
    permission_classes = [
        permissions.IsAuthenticated
    ]  # í”„ë¡ íŠ¸ì—ì„œ ë°”ë””ì— refreshìˆì–´ì•¼í•¨ ( "refresh" : "ë¦¬í”„ë ˆì‰ í† í°")

    def post(self, request):
        refresh_token = request.data.get("refresh")

        if not refresh_token:
            return Response({"detail": "Refresh token is required."}, status=400)

        try:
            token = RefreshToken(refresh_token)
            token.blacklist()
            return Response({"detail": "ë¡œê·¸ì•„ì›ƒ"}, status=204)
        except TokenError as e:
            return Response({"detail": str(e)}, status=400)
        except Exception:
            return Response({"detail": "Invalid request."}, status=400)


class LoginView(TokenObtainPairView):
    serializer_class = CustomTokenObtainPairSerializer


class DeleteUserView(APIView):  # í”„ë¡ íŠ¸ì—ì„œ í—¤ë”ì— access_tokenìˆì–´ì•¼í•¨
    permission_classes = [IsAuthenticated]

    def delete(self, request):
        user = request.user
        user.delete()
        return Response(
            {"detail": "íšŒì› íƒˆí‡´ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}, status=status.HTTP_204_NO_CONTENT
        )


class UpdateUserView(APIView):
    permission_classes = [IsAuthenticated]  # í”„ë¡ íŠ¸ì—ì„œ í—¤ë”ì— access_tokenìˆì–´ì•¼í•¨

    def put(self, request):
        user = request.user  # í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ê°€ì ¸ì˜¤ê¸°
        serializer = UpdateUserSerializer(
            user, data=request.data, partial=True
        )  # partial=Trueë¡œ í•˜ë©´ ì¼ë¶€ë§Œ ìˆ˜ì • ê°€ëŠ¥
        if serializer.is_valid():
            serializer.save()
            return Response(
                {"detail": "íšŒì›ì •ë³´ê°€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤."},
                status=status.HTTP_200_OK,
            )
        else:
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

################################################################################################
# prompt test
################################################################################################
from django.conf import settings
from django.http import JsonResponse, StreamingHttpResponse
from google import genai
from django.views.decorators.csrf import csrf_exempt
import json

import os
import pandas as pd
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate

from sqlalchemy import create_engine
from langchain_chroma import Chroma
from sentence_transformers import SentenceTransformer
from langchain.embeddings.base import Embeddings

from langgraph.graph import StateGraph, END
from langchain_core.tools import tool
from langchain_core.runnables import RunnableLambda
from typing_extensions import TypedDict, Optional
import logging

# =============================================
# GEMINI API KEY ë“±ë¡
# =============================================
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
os.environ["GOOGLE_API_KEY"] = api_key

# =============================================
# MySQL ì—°ê²° ì„¤ì •
# =============================================
user = os.getenv("DB_USER")
password = os.getenv("DB_PASSWORD")
host = os.getenv("SERVER_HOST")
port = "3306"
database = os.getenv("DB_NAME")

# =============================================
# ì„ë² ë”© ëª¨ë¸ ì •ì˜
# =============================================
class SentenceTransformerEmbeddings(Embeddings):
    def __init__(self, model):
        self.model = model

    def embed_documents(self, texts):
        return self.model.encode(texts, show_progress_bar=False).tolist()

    def embed_query(self, text):
        return self.model.encode([text], show_progress_bar=False)[0].tolist()

# =============================================
# ìƒíƒœ ì •ì˜
# =============================================
class StateDict(TypedDict):
    user_prompt: str
    product1: str
    product2: str
    reviews_data1: Optional[str]
    reviews_data2: Optional[str]
    products_data: Optional[str]
    final_docs: Optional[str]
    context: Optional[str]
    llm_response: Optional[str]
    error: Optional[str]

# =============================================
# Tool ì •ì˜ (ê¸°ëŠ¥ë³„ë¡œ ë¶„ë¦¬)
# =============================================
@tool(description="ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œí’ˆ ë¦¬ë·°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
def search_reviews_vector(product_id: str, user_prompt:str)-> dict:
     
    if not user_prompt:
        raise ValueError("Prompt is required")  # Django response ë§ê³  ì˜ˆì™¸ë¡œ ì²˜ë¦¬
    try:
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ìºì‹± ê³ ë ¤)
        embedding_model = SentenceTransformer("intfloat/multilingual-e5-large-instruct")
        embeddings = SentenceTransformerEmbeddings(embedding_model)

        # ChromaDB ì—°ê²°
        vectordb = Chroma(
            persist_directory=f"./vectordb/reviews/product_{product_id}",
            collection_name=f"reviews_product_{product_id}",
            embedding_function=embeddings
        )

        # ê²€ìƒ‰ ì‹¤í–‰
        retriever = vectordb.as_retriever(search_kwargs={"k": 30})
        docs = retriever.invoke(user_prompt)

        # ê²°ê³¼ í¬ë§·íŒ…
        reviews_data = "\n".join([
            f"[ì œí’ˆ{product_id} ë¦¬ë·°]: {doc.page_content}\n[ë©”íƒ€ë°ì´í„°]: {doc.metadata}" 
            for doc in docs
        ])

        return {
            "success": True,
            "data": reviews_data,
            "count": len(docs)
        }

    except Exception as e:
        logging.error(f"Error searching reviews for product {product_id}: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "data": ""
        }

    except Exception as e:
        logging.error(f"Error searching reviews for product {product_id}: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "data": ""
        }
    
@tool(description="MySQL ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œí’ˆ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_products_info(product1: str, product2: str)->dict:
    # MySQLì—ì„œ product ì •ë³´ ë¡œë“œ
    try:
        engine = create_engine(
            f"mysql+pymysql://{user}:{password}@{host}:{port}/{database}?charset=utf8mb4"
        )
        query = f"SELECT * FROM products WHERE id IN ({product1}, {product2})"
        products_df = pd.read_sql(query, con=engine)

        products_data = "\n".join([
            f"[ì œí’ˆ ì •ë³´]: {row.to_dict()}" 
            for _, row in products_df.iterrows()
        ])

        return {
            "success": True,
            "data": products_data
        }

    except Exception as e:
        logging.error(f"Error getting product info: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "data": ""
        }
    
# =============================================
# ë…¸ë“œ í•¨ìˆ˜
# =============================================
def load_reviews_node(state: StateDict) -> StateDict:
    """ë¦¬ë·° ë°ì´í„° ë¡œë“œ ë…¸ë“œ"""
    if state.get("error"):
        return state
    
    user_prompt = state["user_prompt"]
    product1 = state["product1"]
    product2 = state["product2"]
    
    # search_reviews_vector Tool ì‚¬ìš©í•´ì„œ ë¦¬ë·° ê²€ìƒ‰
    result1 = search_reviews_vector.invoke({"product_id": product1, "user_prompt": user_prompt})
    result2 = search_reviews_vector.invoke({"product_id": product2, "user_prompt": user_prompt})
    
    if not result1["success"] or not result2["success"]:
        return {
            **state,
            "error": f"Failed to load reviews: {result1.get('error', '')} {result2.get('error', '')}"
        }
    
    return {
        **state, # ë”•ì…”ë„ˆë¦¬ ì–¸íŒ¨í‚¹ í›„ ìƒˆë¡œìš´ ë°ì´í„° í¬í•¨
        "reviews_data1": result1["data"],
        "reviews_data2": result2["data"]
    }

def load_products_node(state: StateDict) -> StateDict:
    """ì œí’ˆ ì •ë³´ ë¡œë“œ ë…¸ë“œ"""
    if state.get("error"):
        return state
    
    product1 = state["product1"]
    product2 = state["product2"]
    
    # Tool ì‚¬ìš©í•´ì„œ ì œí’ˆ ì •ë³´ ì¡°íšŒ
    result = get_products_info.invoke({"product1": product1, "product2": product2})
    
    if not result["success"]:
        return {
            **state,
            "error": f"Failed to load product info: {result.get('error', '')}"
        }
    
    return {
        **state,
        "products_data": result["data"]
    }

def combine_data_node(state: StateDict) -> StateDict:
    """ë°ì´í„°ë¥¼ ê²°í•©í•˜ëŠ” ë…¸ë“œ"""
    if state.get("error"):
        return state
    
    reviews_data1 = state.get("reviews_data1", "")
    reviews_data2 = state.get("reviews_data2", "")
    products_data = state.get("products_data", "")
    
    final_docs = f"{reviews_data1}\n\n{reviews_data2}\n\n{products_data}"
    
    return {
        **state,
        "final_docs": final_docs,
        "context": state["user_prompt"]
    }

# =============================================
# ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜
# =============================================
def check_error(state: StateDict) -> str:
    """ì—ëŸ¬ ìƒíƒœ í™•ì¸"""
    if state.get("error"):
        return "error"
    return "continue"

# =============================================
# ê·¸ë˜í”„ êµ¬ì„±
# =============================================
def create_data_processing_graph():
    """ë°ì´í„° ì²˜ë¦¬ ê·¸ë˜í”„ ìƒì„±"""
    workflow = StateGraph(StateDict)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("load_reviews", load_reviews_node)
    workflow.add_node("load_products", load_products_node)
    workflow.add_node("combine_data", combine_data_node)
    
    # ì—£ì§€ ì„¤ì •
    workflow.set_entry_point("load_reviews")
    
    # ì¡°ê±´ë¶€ ì—£ì§€    
    workflow.add_conditional_edges(
        "load_reviews",
        check_error,
        {
            "error": END,
            "continue": "load_products"
        }
    )
    
    workflow.add_conditional_edges(
        "load_products",
        check_error,
        {
            "error": END,
            "continue": "combine_data"
        }
    )
    
    workflow.add_edge("combine_data", END)
    
    return workflow.compile()

# =============================================
# ì „ì—­ ë³€ìˆ˜ë¡œ ê·¸ë˜í”„ ìƒì„±
# =============================================
app = create_data_processing_graph()

# =============================================
# Django view
# =============================================
@csrf_exempt
def gemini_streaming(request):
    if request.method != "POST":
        return JsonResponse({"error": "Only POST method is allowed"}, status=405)

    try:
        body = json.loads(request.body)
        user_prompt = body.get("user_prompt", "").strip()
        product1 = body.get("product1", "").strip()
        product2 = body.get("product2", "").strip()

        if not user_prompt:
            return JsonResponse({"error": "Prompt is required"}, status=400)

        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        state = {
            "user_prompt": user_prompt,
            "product1": product1,
            "product2": product2,
            "reviews_data1": None,
            "reviews_data2": None,
            "products_data": None,
            "final_docs": None,
            "context": None,
            "llm_response": None,
            "error": None
        }

        # LangGraph ì‹¤í–‰
        result = app.invoke(state)  

        if result.get("error"):
            return JsonResponse({"error": result["error"]}, statue=4000)
        
        final_docs = result["final_docs"]
        user_prompt = result["context"]

    except Exception as e:
        import traceback, sys
        traceback.print_exc(file=sys.stderr)
        return JsonResponse({"error": f"Invalid input: {str(e)}"}, status=400)

    prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            """ë„ˆëŠ” ë‘ ì œí’ˆì˜ ë¦¬ë·° ë°ì´í„°ë¥¼ ë¹„êµí•˜ê³  ë¶„ì„í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì•¼. 
            íƒ€ì‚¬ ì œí’ˆ ëŒ€ë¹„ ìì‚¬ ì œí’ˆì˜ ì¥ë‹¨ì ì„ íŒŒì•…í•˜ê³  ê°œì„ ì ì„ ì°¾ê¸° ìœ„í•´ 
            ê·¸ì— ë§ëŠ” ë¦¬í¬íŠ¸ ë‚´ë¶€ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µ í•´ì¤˜.
            product1ì€ ìì‚¬ ì œí’ˆì´ê³ , product2ëŠ” ê²½ìŸì‚¬ ì œí’ˆì´ì•¼.

            ì œí•œëœ í† í° ì•ˆì—ì„œ ë‚´ìš©ì´ ë¶€ì •í™•í•˜ê±°ë‚˜ ë‹µë³€ì´ ëŠê¸°ëŠ” ë“± ì œí’ˆ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ëª¨í˜¸í•´ì§€ë©´ ì•ˆë¼.
            ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ê³ , ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ëª¨ë¥¸ë‹¤ê³  ë‹µí•´ì¤˜."""
        ),
        ("user", "ìš”ì²­: {user_prompt}\n\nContext:\n{final_docs}")
    ])

    formatted_prompt = prompt.format(
        user_prompt=user_prompt,
        final_docs=final_docs
    )
    
    # Gemini API
    client = genai.Client(api_key=settings.GEMINI_API_KEY)
    stream = client.models.generate_content_stream(
        model="gemini-2.0-flash",
        contents=formatted_prompt,
        #eneration_config={
        #max_output_tokens":state["input"]["max_tokens"]
        #
    )

    def gen():
        try:
            for chunk in stream:
                # Check if chunk has text content
                if hasattr(chunk, 'text') and chunk.text:
                    print(f"Sending chunk: {chunk.text[:50]}...")  # Debug print
                    # Wrap with SSE format
                    yield f"data: {json.dumps({'text': chunk.text})}\n\n"
        except Exception as e:
            print(f"Streaming error: {e}")
            yield f"data: {json.dumps({'error': str(e)})}\n\n"

    return StreamingHttpResponse(
        gen(),
        content_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"}
    )
